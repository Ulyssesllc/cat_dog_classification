{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 6633136,
          "sourceType": "datasetVersion",
          "datasetId": 3829311
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Cats vs Dogs Classification with Resnet",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ulyssesllc/cat_dog_classification/blob/main/Cats_vs_Dogs_Classification_with_Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "bhavikjikadara_dog_and_cat_classification_dataset_path = kagglehub.dataset_download('bhavikjikadara/dog-and-cat-classification-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "DPALyIdz8FPf"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I) Import and download"
      ],
      "metadata": {
        "id": "1Oiuu4w38FPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from torch import nn\n",
        "from shutil import copyfile\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-22T01:26:30.540609Z",
          "iopub.execute_input": "2025-03-22T01:26:30.541049Z",
          "iopub.status.idle": "2025-03-22T01:26:30.545326Z",
          "shell.execute_reply.started": "2025-03-22T01:26:30.541021Z",
          "shell.execute_reply": "2025-03-22T01:26:30.544293Z"
        },
        "trusted": true,
        "id": "VIo1TuDK8FPi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T01:26:33.135981Z",
          "iopub.execute_input": "2025-03-22T01:26:33.136334Z",
          "iopub.status.idle": "2025-03-22T01:26:33.188519Z",
          "shell.execute_reply.started": "2025-03-22T01:26:33.136304Z",
          "shell.execute_reply": "2025-03-22T01:26:33.187783Z"
        },
        "id": "SU7ALr2n8FPi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II) The dataset"
      ],
      "metadata": {
        "id": "c8yPdhQd8FPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *) Loading the dataset"
      ],
      "metadata": {
        "id": "eTiatSoN8FPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_folder='/kaggle/input/dog-and-cat-classification-dataset/PetImages'\n",
        "cat_folder= os.path.join(root_folder,\"Cat\")\n",
        "print(cat_folder)"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:29.256417Z",
          "iopub.status.busy": "2025-03-21T08:33:29.256054Z",
          "iopub.status.idle": "2025-03-21T08:33:29.261479Z",
          "shell.execute_reply": "2025-03-21T08:33:29.260621Z",
          "shell.execute_reply.started": "2025-03-21T08:33:29.256396Z"
        },
        "trusted": true,
        "id": "xjClUFki8FPj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II.1) Overview"
      ],
      "metadata": {
        "id": "SRIsWSvw8FPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_img= os.listdir(cat_folder)\n",
        "print(len(cat_img))\n",
        "print(cat_img[:5])"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:29.262548Z",
          "iopub.status.busy": "2025-03-21T08:33:29.262293Z",
          "iopub.status.idle": "2025-03-21T08:33:29.426569Z",
          "shell.execute_reply": "2025-03-21T08:33:29.425596Z",
          "shell.execute_reply.started": "2025-03-21T08:33:29.262528Z"
        },
        "trusted": true,
        "id": "-p84RS658FPj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cat_img_paths= [os.path.join(cat_folder, img) for img in cat_img]\n",
        "print(cat_img_paths[:5])"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:29.427609Z",
          "iopub.status.busy": "2025-03-21T08:33:29.427297Z",
          "iopub.status.idle": "2025-03-21T08:33:29.444765Z",
          "shell.execute_reply": "2025-03-21T08:33:29.443931Z",
          "shell.execute_reply.started": "2025-03-21T08:33:29.427586Z"
        },
        "trusted": true,
        "id": "sBZE8hzU8FPk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(5,2, figsize=(10,20))\n",
        "ten_img= cat_img_paths[:10]\n",
        "\n",
        "for i, img in enumerate(ten_img):\n",
        "    print(img)\n",
        "    ax = axes[i//2,i%2]\n",
        "    ax.imshow(plt.imread(img))\n",
        "    ax.title.set_text(os.path.basename(img))\n",
        "    ax.axis('on')\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:29.445995Z",
          "iopub.status.busy": "2025-03-21T08:33:29.445662Z",
          "iopub.status.idle": "2025-03-21T08:33:32.239531Z",
          "shell.execute_reply": "2025-03-21T08:33:32.23823Z",
          "shell.execute_reply.started": "2025-03-21T08:33:29.445963Z"
        },
        "trusted": true,
        "id": "OrrG7sN98FPk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II.2) Train & test split"
      ],
      "metadata": {
        "id": "FIDxROhu8FPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    os.mkdir('/tmp/cats-v-dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training')\n",
        "    os.mkdir('/tmp/cats-v-dogs/validation')\n",
        "    os.mkdir('/tmp/cats-v-dogs/test')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/validation/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/validation/dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/test/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/test/dogs')\n",
        "except OSError:\n",
        "    print('Error failed to make directory')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:32.242233Z",
          "iopub.status.busy": "2025-03-21T08:33:32.24198Z",
          "iopub.status.idle": "2025-03-21T08:33:32.249303Z",
          "shell.execute_reply": "2025-03-21T08:33:32.248583Z",
          "shell.execute_reply.started": "2025-03-21T08:33:32.242214Z"
        },
        "trusted": true,
        "id": "nxhKTHrl8FPl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****As we can see, the paths are yet to be created, so it's our mission to do that beforehand****"
      ],
      "metadata": {
        "id": "S3_8Odsi8FPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "cat_path = '/kaggle/input/dog-and-cat-classification-dataset/PetImages/Cat'\n",
        "dog_path = '/kaggle/input/dog-and-cat-classification-dataset/PetImages/Dog'\n",
        "\n",
        "training_path = '/tmp/cats-v-dogs/training'\n",
        "validation_path = '/tmp/cats-v-dogs/validation'\n",
        "\n",
        "training_dog = os.path.join(training_path, 'dogs/')\n",
        "validation_dog = os.path.join(validation_path, 'dogs/')\n",
        "\n",
        "training_cat = os.path.join(training_path, 'cats/')\n",
        "validation_cat = os.path.join(validation_path, 'cats/')\n",
        "\n",
        "# Define whether to test split or not\n",
        "include_test= True"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:32.250875Z",
          "iopub.status.busy": "2025-03-21T08:33:32.250687Z",
          "iopub.status.idle": "2025-03-21T08:33:32.266462Z",
          "shell.execute_reply": "2025-03-21T08:33:32.265559Z",
          "shell.execute_reply.started": "2025-03-21T08:33:32.250859Z"
        },
        "trusted": true,
        "id": "dPFPhX0a8FPl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs')))\n",
        "\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/validation/cats')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/validation/dogs')))\n",
        "\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/test/cats')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/test/dogs')))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:32.267594Z",
          "iopub.status.busy": "2025-03-21T08:33:32.26735Z",
          "iopub.status.idle": "2025-03-21T08:33:32.287606Z",
          "shell.execute_reply": "2025-03-21T08:33:32.286888Z",
          "shell.execute_reply.started": "2025-03-21T08:33:32.267572Z"
        },
        "trusted": true,
        "id": "4gmIdu6e8FPm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Now we will create a function to split the data****"
      ],
      "metadata": {
        "id": "n-QcYhSp8FPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(main_dir, training_dir, validation_dir, test_dir=None, include_test_split = True,  split_size=0.9):\n",
        "    \"\"\"\n",
        "    Splits the data into train validation and test sets (optional)\n",
        "\n",
        "    Args:\n",
        "    main_dir (string):  path containing the images\n",
        "    training_dir (string):  path to be used for training\n",
        "    validation_dir (string):  path to be used for validation\n",
        "    test_dir (string):  path to be used for test\n",
        "    include_test_split (boolen):  whether to include a test split or not\n",
        "    split_size (float): size of the dataset to be used for training\n",
        "    \"\"\"\n",
        "    files = []\n",
        "    for file in os.listdir(main_dir):\n",
        "        if  os.path.getsize(os.path.join(main_dir, file)): # check if the file's size isn't 0\n",
        "            files.append(file) # appends file name to a list\n",
        "\n",
        "    shuffled_files = random.sample(files,  len(files)) # shuffles the data\n",
        "    split = int(0.9 * len(shuffled_files)) #the training split casted into int for numeric rounding\n",
        "    train = shuffled_files[:split] #training split\n",
        "    split_valid_test = int(split + (len(shuffled_files)-split)/2)\n",
        "\n",
        "    if include_test_split:\n",
        "        validation = shuffled_files[split:split_valid_test] # validation split\n",
        "        test = shuffled_files[split_valid_test:]\n",
        "    else:\n",
        "        validation = shuffled_files[split:]\n",
        "\n",
        "    for element in train:\n",
        "        copyfile(os.path.join(main_dir,  element), os.path.join(training_dir, element)) # copy files into training directory\n",
        "\n",
        "    for element in validation:\n",
        "        copyfile(os.path.join(main_dir,  element), os.path.join(validation_dir, element))# copy files into validation directory\n",
        "\n",
        "    if include_test_split:\n",
        "        for element in test:\n",
        "            copyfile(os.path.join(main_dir,  element), os.path.join(test_dir, element)) # copy files into test directory\n",
        "    print(\"Split successful!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:32.288725Z",
          "iopub.status.busy": "2025-03-21T08:33:32.288453Z",
          "iopub.status.idle": "2025-03-21T08:33:32.309212Z",
          "shell.execute_reply": "2025-03-21T08:33:32.308628Z",
          "shell.execute_reply.started": "2025-03-21T08:33:32.288696Z"
        },
        "trusted": true,
        "id": "h7qSvPhh8FPm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "split_data(cat_path, '/tmp/cats-v-dogs/training/cats', '/tmp/cats-v-dogs/validation/cats', '/tmp/cats-v-dogs/test/cats',include_test, 0.9)\n",
        "split_data(dog_path, '/tmp/cats-v-dogs/training/dogs', '/tmp/cats-v-dogs/validation/dogs','/tmp/cats-v-dogs/test/dogs',include_test, 0.9)"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.95Z",
          "iopub.execute_input": "2025-03-21T08:33:32.310073Z",
          "iopub.status.busy": "2025-03-21T08:33:32.309847Z"
        },
        "trusted": true,
        "id": "RpnZLz5G8FPn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Now, lets check on the number of files stored in each recently created directories****"
      ],
      "metadata": {
        "id": "yRAXXoKv8FPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs')))\n",
        "\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/validation/cats')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/validation/dogs')))\n",
        "\n",
        "\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/test/cats')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/test/dogs')))"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.951Z"
        },
        "trusted": true,
        "id": "GSd8CPOW8FPn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II.3) Creation of image loaders"
      ],
      "metadata": {
        "id": "aFLdrg-18FPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "****First, we define the transformation****"
      ],
      "metadata": {
        "id": "bOtX5EQR8FPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, datasets\n",
        "from torchvision.transforms import RandAugment\n",
        "\n",
        "# Training transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    RandAugment(num_ops=2, magnitude=9),  # RandAugment for robustness\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.RandomErasing(p=0.1),  # Random erase for regularization\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "VCienlAL8FPn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation & testing transforms (no augmentation)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "id": "rjpNtZ6Y8FPo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Then, we create data loaders for previewing the images****"
      ],
      "metadata": {
        "id": "gbElY7Pz8FPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder(root='/tmp/cats-v-dogs/training', transform=train_transform)\n",
        "val_dataset = datasets.ImageFolder(root='/tmp/cats-v-dogs/validation', transform=transform)\n",
        "\n",
        "if include_test:\n",
        "    test_dataset = datasets.ImageFolder(root='/tmp/cats-v-dogs/validation', transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "if include_test:\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "xnCgPHU28FPo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Now, make sure we got the correct data****"
      ],
      "metadata": {
        "id": "MAeYXMWt8FPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Cat', 'Dog']\n",
        "\n",
        "def plot_data(data_loader, n_images):\n",
        "    \"\"\"\n",
        "    Plots random data from a PyTorch DataLoader\n",
        "    Args:\n",
        "        data_loader: a PyTorch DataLoader instance\n",
        "        n_images: number of images to plot\n",
        "    \"\"\"\n",
        "    # Fetch a batch of images and labels\n",
        "    images, labels = next(iter(data_loader))  # Use iter() and next() to get a batch\n",
        "\n",
        "    # Calculate the number of rows and columns for subplots\n",
        "    n_cols = 3  # Number of columns in the plot\n",
        "    n_rows = (n_images + n_cols - 1) // n_cols  # Calculate rows dynamically\n",
        "\n",
        "    plt.figure(figsize=(14, 15))\n",
        "\n",
        "    for i in range(n_images):\n",
        "        plt.subplot(n_rows, n_cols, i + 1)\n",
        "        image = images[i].permute(1, 2, 0)  # Convert from (C, H, W) to (H, W, C) for matplotlib\n",
        "        if image.shape[-1] == 1:  # Grayscale image\n",
        "            plt.imshow(image.squeeze(), cmap='gray')\n",
        "        else:  # RGB image\n",
        "            plt.imshow(image)\n",
        "        plt.title(class_names[labels[i].item()])  # Get the label as a Python scalar\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "Io2KmL1W8FPo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data(train_loader, n_images=6)"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "spHuQOqC8FPp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data(val_loader, n_images=6)"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "w79I5iYs8FPp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "if include_test:\n",
        "    plot_data(test_loader, n_images=9)"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "zDEqg2-P8FPp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III) Model"
      ],
      "metadata": {
        "id": "RhaGWPHz8FPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bottleneck Blocks**"
      ],
      "metadata": {
        "id": "7CaFBYsd8FPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class BottleneckD(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "        mid_channels = planes\n",
        "\n",
        "        # Main path\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.conv1 = nn.Conv2d(inplanes, mid_channels, 1, bias=False)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
        "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, 3,\n",
        "                              stride=stride, padding=1, bias=False)\n",
        "\n",
        "        self.bn3 = nn.BatchNorm2d(mid_channels)\n",
        "        self.conv3 = nn.Conv2d(mid_channels, planes * self.expansion, 1, bias=False)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = F.relu(self.bn1(x), inplace=True)\n",
        "        out = self.conv1(out)\n",
        "\n",
        "        out = F.relu(self.bn2(out), inplace=True)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        out = F.relu(self.bn3(out), inplace=True)\n",
        "        out = self.conv3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        return F.relu(out, inplace=True)\n"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "U833u-uR8FPq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Define ResNet-50 architecture****"
      ],
      "metadata": {
        "id": "iX4Qn0uP8FPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet50D(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.inplanes = 64\n",
        "\n",
        "        # ResNet-D Stem\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        # Layers\n",
        "        self.layer1 = self._make_layer(BottleneckD, 64, 3, stride=1)\n",
        "        self.layer2 = self._make_layer(BottleneckD, 128, 4, stride=2)\n",
        "        self.layer3 = self._make_layer(BottleneckD, 256, 6, stride=2)\n",
        "        self.layer4 = self._make_layer(BottleneckD, 512, 3, stride=2)\n",
        "\n",
        "        # Head\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * BottleneckD.expansion, num_classes)\n",
        "\n",
        "        # Initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample_layers = []\n",
        "\n",
        "            if stride != 1:\n",
        "                downsample_layers.append(\n",
        "                    nn.AvgPool2d(kernel_size=2, stride=stride, ceil_mode=True)\n",
        "                )\n",
        "\n",
        "            downsample_layers.extend([\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion, 1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion)\n",
        "            ])\n",
        "\n",
        "            downsample = nn.Sequential(*downsample_layers)\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "id": "3XF8C6fL8FPq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50D(num_classes=2).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "h3TBKCf08FPr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Now we define the loss function and optimizer used for the model****"
      ],
      "metadata": {
        "id": "gye6GGIC8FPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.amp import GradScaler\n",
        "\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer (in this case Adam)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.05)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=10)  # LR scheduler\n",
        "\n",
        "# Mixed precision\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "SrXMcT9W8FPx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV) Evaluation"
      ],
      "metadata": {
        "id": "BIohOFes8FPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "****After all those implementations and setups, we are ready to run the model and present the results****"
      ],
      "metadata": {
        "id": "MRVIUyo88FPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast\n",
        "from tqdm import tqdm  # For progress bars"
      ],
      "metadata": {
        "trusted": true,
        "id": "IS4eVKVV8FPy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training Phase ---\n",
        "def train(model, train_loader, criterion, optimizer, scaler, epoch):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    return train_loss / len(train_loader), 100. * correct / total"
      ],
      "metadata": {
        "trusted": true,
        "id": "GRq_L6Ny8FPy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Validation Phase ---\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=\"Validating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    return val_loss / len(val_loader), 100. * correct / total"
      ],
      "metadata": {
        "trusted": true,
        "id": "NMA27sjG8FPy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store training and validation metrics\n",
        "train_loss_history = []\n",
        "train_acc_history = []\n",
        "val_loss_history = []\n",
        "val_acc_history = []\n",
        "best_acc = 0.0\n",
        "\n",
        "# Initialize the loop\n",
        "for epoch in range(16):\n",
        "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, scaler, epoch)\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
        "    scheduler.step()\n",
        "\n",
        "    # Store the training and testing data\n",
        "    train_loss_history.append(train_loss)\n",
        "    train_acc_history.append(train_acc)\n",
        "    val_loss_history.append(val_loss)\n",
        "    val_acc_history.append(val_acc)\n",
        "\n",
        "    # Save model with best performance\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_resnet50d_randaug_tta.pth\")\n",
        "\n",
        "    print(f\"Epoch {epoch}: Train Loss: {train_loss:.4f} | Val Acc: {val_acc:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "9eqNDZco8FPy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Now we make evaluations on the test data****"
      ],
      "metadata": {
        "id": "ULIUqgit8FPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model weights\n",
        "model.load_state_dict(torch.load(\"best_resnet50d_randaug_tta.pth\"))\n",
        "model.to(device)  # Ensure model is on the correct device\n",
        "\n",
        "# Run testing\n",
        "if include_test:\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=\"Testing\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    # Compute average loss and accuracy\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = 100 * correct / total\n",
        "\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "-vLMauzC8FPz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV.1) Visualize the prediction"
      ],
      "metadata": {
        "id": "T-pCnF_S8FPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_prediction(data_loader, model, n_images, class_names):\n",
        "    \"\"\"\n",
        "    Test the model on random predictions\n",
        "    Args:\n",
        "        data_loader: PyTorch DataLoader instance\n",
        "        model: Trained PyTorch model\n",
        "        n_images: Number of images to plot\n",
        "        class_names: List of class names (e.g., ['Cat', 'Dog'])\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    images, labels = next(iter(data_loader))  # Fetch a batch of images and labels\n",
        "\n",
        "    # Move images and labels to the appropriate device (e.g., GPU if available)\n",
        "    device = next(model.parameters()).device\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Get model predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)  # Get the predicted class indices\n",
        "\n",
        "    # Convert tensors to numpy arrays for visualization\n",
        "    images = images.cpu().numpy()\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    # Plot the images with predictions\n",
        "    plt.figure(figsize=(14, 15))\n",
        "    for i in range(min(n_images, len(images))):  # Ensure we don't exceed the batch size\n",
        "        plt.subplot(4, 3, i + 1)\n",
        "        image = np.transpose(images[i], (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
        "        if images[i].shape[0] == 1:  # Grayscale image\n",
        "            image = image.squeeze()\n",
        "            plt.imshow(image, cmap='gray')\n",
        "        else:  # RGB image\n",
        "            plt.imshow(image)\n",
        "\n",
        "        # Set title color based on prediction correctness\n",
        "        if predictions[i] == labels[i]:\n",
        "            title_obj = plt.title(f\"True: {class_names[labels[i]]}\\nPred: {class_names[predictions[i]]}\", color='g')\n",
        "        else:\n",
        "            title_obj = plt.title(f\"True: {class_names[labels[i]]}\\nPred: {class_names[predictions[i]]}\", color='r')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "bk6hfoa-8FPz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction(val_loader, model, n_images=9, class_names=['Cat','Dog'])"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "tJebVQfc8FPz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "if include_test:\n",
        "    plot_prediction(test_loader, model, n_images=9, class_names=['Cat','Dog'])"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "nBg7Y40t8FPz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV.2) Visualize training process"
      ],
      "metadata": {
        "id": "U-liUyGd8FP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to store the training history\n",
        "results = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_loss_history) + 1),\n",
        "    'train_loss': train_loss_history,\n",
        "    'train_acc': train_acc_history,\n",
        "    'val_loss': val_loss_history,\n",
        "    'val_acc': val_acc_history\n",
        "})\n",
        "\n",
        "# Display the last few rows of the DataFrame\n",
        "print(results.tail())"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "PYSZhsMP8FP0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(results['epoch'], results['train_loss'], label='Train Loss')\n",
        "plt.plot(results['epoch'], results['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "9e7NCQCC8FP1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(results['epoch'], results['train_acc'], label='Train Accuracy')\n",
        "plt.plot(results['epoch'], results['val_acc'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "tI6OWfh08FP1"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}