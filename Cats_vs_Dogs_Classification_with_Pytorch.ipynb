{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 6633136,
          "sourceType": "datasetVersion",
          "datasetId": 3829311
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Cats vs Dogs Classification with Pytorch",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ulyssesllc/cat_dog_classification/blob/main/Cats_vs_Dogs_Classification_with_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "bhavikjikadara_dog_and_cat_classification_dataset_path = kagglehub.dataset_download('bhavikjikadara/dog-and-cat-classification-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l68Bf5DP6jXc",
        "outputId": "a7695162-b0e9-41e1-8817-77620c9c85ed"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I) Import and download"
      ],
      "metadata": {
        "id": "dY9m1u366jXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from torch import nn\n",
        "from shutil import copyfile\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-22T01:26:30.540609Z",
          "iopub.execute_input": "2025-03-22T01:26:30.541049Z",
          "iopub.status.idle": "2025-03-22T01:26:30.545326Z",
          "shell.execute_reply.started": "2025-03-22T01:26:30.541021Z",
          "shell.execute_reply": "2025-03-22T01:26:30.544293Z"
        },
        "trusted": true,
        "id": "vmikONnK6jXh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T01:26:33.135981Z",
          "iopub.execute_input": "2025-03-22T01:26:33.136334Z",
          "iopub.status.idle": "2025-03-22T01:26:33.188519Z",
          "shell.execute_reply.started": "2025-03-22T01:26:33.136304Z",
          "shell.execute_reply": "2025-03-22T01:26:33.187783Z"
        },
        "id": "fTgsWzpY6jXh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II) The dataset"
      ],
      "metadata": {
        "id": "wR1tYWwa6jXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *) Loading the dataset"
      ],
      "metadata": {
        "id": "EsmzAVK-6jXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_folder='/kaggle/input/dog-and-cat-classification-dataset/PetImages'\n",
        "cat_folder= os.path.join(root_folder,\"Cat\")\n",
        "print(cat_folder)"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:29.256417Z",
          "iopub.status.busy": "2025-03-21T08:33:29.256054Z",
          "iopub.status.idle": "2025-03-21T08:33:29.261479Z",
          "shell.execute_reply": "2025-03-21T08:33:29.260621Z",
          "shell.execute_reply.started": "2025-03-21T08:33:29.256396Z"
        },
        "trusted": true,
        "id": "RTYksP2c6jXi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II.1) Overview"
      ],
      "metadata": {
        "id": "FF_qoJgM6jXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_img= os.listdir(cat_folder)\n",
        "print(len(cat_img))\n",
        "print(cat_img[:5])"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:29.262548Z",
          "iopub.status.busy": "2025-03-21T08:33:29.262293Z",
          "iopub.status.idle": "2025-03-21T08:33:29.426569Z",
          "shell.execute_reply": "2025-03-21T08:33:29.425596Z",
          "shell.execute_reply.started": "2025-03-21T08:33:29.262528Z"
        },
        "trusted": true,
        "id": "XfLmQzVr6jXj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cat_img_paths= [os.path.join(cat_folder, img) for img in cat_img]\n",
        "print(cat_img_paths[:5])"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:29.427609Z",
          "iopub.status.busy": "2025-03-21T08:33:29.427297Z",
          "iopub.status.idle": "2025-03-21T08:33:29.444765Z",
          "shell.execute_reply": "2025-03-21T08:33:29.443931Z",
          "shell.execute_reply.started": "2025-03-21T08:33:29.427586Z"
        },
        "trusted": true,
        "id": "YwSM44Pj6jXk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(5,2, figsize=(10,20))\n",
        "ten_img= cat_img_paths[:10]\n",
        "\n",
        "for i, img in enumerate(ten_img):\n",
        "    print(img)\n",
        "    ax = axes[i//2,i%2]\n",
        "    ax.imshow(plt.imread(img))\n",
        "    ax.title.set_text(os.path.basename(img))\n",
        "    ax.axis('on')\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:29.445995Z",
          "iopub.status.busy": "2025-03-21T08:33:29.445662Z",
          "iopub.status.idle": "2025-03-21T08:33:32.239531Z",
          "shell.execute_reply": "2025-03-21T08:33:32.23823Z",
          "shell.execute_reply.started": "2025-03-21T08:33:29.445963Z"
        },
        "trusted": true,
        "id": "_YV4aOET6jXk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II.2) Train & test split"
      ],
      "metadata": {
        "id": "sKHlMmXW6jXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    os.mkdir('/tmp/cats-v-dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training')\n",
        "    os.mkdir('/tmp/cats-v-dogs/validation')\n",
        "    os.mkdir('/tmp/cats-v-dogs/test')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/validation/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/validation/dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/test/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/test/dogs')\n",
        "except OSError:\n",
        "    print('Error failed to make directory')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:32.242233Z",
          "iopub.status.busy": "2025-03-21T08:33:32.24198Z",
          "iopub.status.idle": "2025-03-21T08:33:32.249303Z",
          "shell.execute_reply": "2025-03-21T08:33:32.248583Z",
          "shell.execute_reply.started": "2025-03-21T08:33:32.242214Z"
        },
        "trusted": true,
        "id": "zeBQ_wlD6jXl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****As we can see, the paths are yet to be created, so it's our mission to do that beforehand****"
      ],
      "metadata": {
        "id": "5Z6WVagG6jXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "cat_path = '/kaggle/input/dog-and-cat-classification-dataset/PetImages/Cat'\n",
        "dog_path = '/kaggle/input/dog-and-cat-classification-dataset/PetImages/Dog'\n",
        "\n",
        "training_path = '/tmp/cats-v-dogs/training'\n",
        "validation_path = '/tmp/cats-v-dogs/validation'\n",
        "\n",
        "training_dog = os.path.join(training_path, 'dogs/')\n",
        "validation_dog = os.path.join(validation_path, 'dogs/')\n",
        "\n",
        "training_cat = os.path.join(training_path, 'cats/')\n",
        "validation_cat = os.path.join(validation_path, 'cats/')\n",
        "\n",
        "# Define whether to test split or not\n",
        "include_test= True"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:32.250875Z",
          "iopub.status.busy": "2025-03-21T08:33:32.250687Z",
          "iopub.status.idle": "2025-03-21T08:33:32.266462Z",
          "shell.execute_reply": "2025-03-21T08:33:32.265559Z",
          "shell.execute_reply.started": "2025-03-21T08:33:32.250859Z"
        },
        "trusted": true,
        "id": "iOwAbvFi6jXl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs')))\n",
        "\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/validation/cats')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/validation/dogs')))\n",
        "\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/test/cats')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/test/dogs')))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:32.267594Z",
          "iopub.status.busy": "2025-03-21T08:33:32.26735Z",
          "iopub.status.idle": "2025-03-21T08:33:32.287606Z",
          "shell.execute_reply": "2025-03-21T08:33:32.286888Z",
          "shell.execute_reply.started": "2025-03-21T08:33:32.267572Z"
        },
        "trusted": true,
        "id": "zpjmvsQt6jXm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Now we will create a function to split the data****"
      ],
      "metadata": {
        "id": "MxNIyqhy6jXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(main_dir, training_dir, validation_dir, test_dir=None, include_test_split = True,  split_size=0.9):\n",
        "    \"\"\"\n",
        "    Splits the data into train validation and test sets (optional)\n",
        "\n",
        "    Args:\n",
        "    main_dir (string):  path containing the images\n",
        "    training_dir (string):  path to be used for training\n",
        "    validation_dir (string):  path to be used for validation\n",
        "    test_dir (string):  path to be used for test\n",
        "    include_test_split (boolen):  whether to include a test split or not\n",
        "    split_size (float): size of the dataset to be used for training\n",
        "    \"\"\"\n",
        "    files = []\n",
        "    for file in os.listdir(main_dir):\n",
        "        if  os.path.getsize(os.path.join(main_dir, file)): # check if the file's size isn't 0\n",
        "            files.append(file) # appends file name to a list\n",
        "\n",
        "    shuffled_files = random.sample(files,  len(files)) # shuffles the data\n",
        "    split = int(0.9 * len(shuffled_files)) #the training split casted into int for numeric rounding\n",
        "    train = shuffled_files[:split] #training split\n",
        "    split_valid_test = int(split + (len(shuffled_files)-split)/2)\n",
        "\n",
        "    if include_test_split:\n",
        "        validation = shuffled_files[split:split_valid_test] # validation split\n",
        "        test = shuffled_files[split_valid_test:]\n",
        "    else:\n",
        "        validation = shuffled_files[split:]\n",
        "\n",
        "    for element in train:\n",
        "        copyfile(os.path.join(main_dir,  element), os.path.join(training_dir, element)) # copy files into training directory\n",
        "\n",
        "    for element in validation:\n",
        "        copyfile(os.path.join(main_dir,  element), os.path.join(validation_dir, element))# copy files into validation directory\n",
        "\n",
        "    if include_test_split:\n",
        "        for element in test:\n",
        "            copyfile(os.path.join(main_dir,  element), os.path.join(test_dir, element)) # copy files into test directory\n",
        "    print(\"Split successful!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-21T08:33:32.288725Z",
          "iopub.status.busy": "2025-03-21T08:33:32.288453Z",
          "iopub.status.idle": "2025-03-21T08:33:32.309212Z",
          "shell.execute_reply": "2025-03-21T08:33:32.308628Z",
          "shell.execute_reply.started": "2025-03-21T08:33:32.288696Z"
        },
        "trusted": true,
        "id": "2j-RqobF6jXm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "split_data(cat_path, '/tmp/cats-v-dogs/training/cats', '/tmp/cats-v-dogs/validation/cats', '/tmp/cats-v-dogs/test/cats',include_test, 0.9)\n",
        "split_data(dog_path, '/tmp/cats-v-dogs/training/dogs', '/tmp/cats-v-dogs/validation/dogs','/tmp/cats-v-dogs/test/dogs',include_test, 0.9)"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.95Z",
          "iopub.execute_input": "2025-03-21T08:33:32.310073Z",
          "iopub.status.busy": "2025-03-21T08:33:32.309847Z"
        },
        "trusted": true,
        "id": "zVkFBfTL6jXm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Now, lets check on the number of files stored in each recently created directories****"
      ],
      "metadata": {
        "id": "v-AJoCku6jXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs')))\n",
        "\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/validation/cats')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/validation/dogs')))\n",
        "\n",
        "\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/test/cats')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/test/dogs')))"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.951Z"
        },
        "trusted": true,
        "id": "KingJuqr6jXm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II.3) Creation of image loaders"
      ],
      "metadata": {
        "id": "1uNUtVMP6jXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "****First, we define the transformation****"
      ],
      "metadata": {
        "id": "WigKfObd6jXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, datasets\n",
        "transform = transforms.Compose([transforms.Resize((150,150)),transforms.ToTensor()])"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "UIN4XUjP6jXn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Then, we create data loaders for previewing the images****"
      ],
      "metadata": {
        "id": "Lh7qZsMl6jXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder(root='/tmp/cats-v-dogs/training', transform=transform)\n",
        "validation_dataset = datasets.ImageFolder(root='/tmp/cats-v-dogs/validation', transform=transform)\n",
        "\n",
        "if include_test:\n",
        "    test_dataset = datasets.ImageFolder(root='/tmp/cats-v-dogs/validation', transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "if include_test:\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "EdtiGmES6jXn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Now, make sure we got the correct data****"
      ],
      "metadata": {
        "id": "cJlzpvwN6jXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Cat', 'Dog']\n",
        "\n",
        "def plot_data(data_loader, n_images):\n",
        "    \"\"\"\n",
        "    Plots random data from a PyTorch DataLoader\n",
        "    Args:\n",
        "        data_loader: a PyTorch DataLoader instance\n",
        "        n_images: number of images to plot\n",
        "    \"\"\"\n",
        "    # Fetch a batch of images and labels\n",
        "    images, labels = next(iter(data_loader))  # Use iter() and next() to get a batch\n",
        "\n",
        "    # Calculate the number of rows and columns for subplots\n",
        "    n_cols = 3  # Number of columns in the plot\n",
        "    n_rows = (n_images + n_cols - 1) // n_cols  # Calculate rows dynamically\n",
        "\n",
        "    plt.figure(figsize=(14, 15))\n",
        "\n",
        "    for i in range(n_images):\n",
        "        plt.subplot(n_rows, n_cols, i + 1)\n",
        "        image = images[i].permute(1, 2, 0)  # Convert from (C, H, W) to (H, W, C) for matplotlib\n",
        "        if image.shape[-1] == 1:  # Grayscale image\n",
        "            plt.imshow(image.squeeze(), cmap='gray')\n",
        "        else:  # RGB image\n",
        "            plt.imshow(image)\n",
        "        plt.title(class_names[labels[i].item()])  # Get the label as a Python scalar\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "qqWYwnYy6jXn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data(train_loader, n_images=6)"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "D3DC-VZK6jXo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data(validation_loader, n_images=6)"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "tJoOEmci6jXo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "if include_test:\n",
        "    plot_data(test_loader, n_images=9)"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "21ggLp7N6jXo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III) Model"
      ],
      "metadata": {
        "id": "-RjOmrFr6jXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers with BatchNorm\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # (64, 75, 75)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # (128, 37, 37)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(256)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # (256, 18, 18)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(256, 512)\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout for regularization\n",
        "        self.fc2 = nn.Linear(512, 2)  # Binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv + BatchNorm + ReLU6\n",
        "        x = F.relu6(self.bn1(self.conv1(x)))\n",
        "        x = F.relu6(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu6(self.bn3(self.conv3(x)))\n",
        "        x = F.relu6(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu6(self.bn5(self.conv5(x)))\n",
        "        x = F.relu6(self.bn6(self.conv6(x)))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        x = self.global_avg_pool(x)\n",
        "\n",
        "        # Flatten the output\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu6(self.fc1(x))\n",
        "        x = self.dropout(x)  # Apply dropout\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x  # No softmax, use nn.CrossEntropyLoss()\n",
        "\n",
        "# Instantiate the model\n",
        "model = CNN()\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "JNxIXMND6jXo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Now we define the loss function and optimizer used for the model****"
      ],
      "metadata": {
        "id": "ahjGlk366jXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer (in this case Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.952Z"
        },
        "trusted": true,
        "id": "dnd8Pq-R6jXp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV) Evaluation"
      ],
      "metadata": {
        "id": "j8tVrJcM6jXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "****After all those implementations and setups, we are ready to run the model and present the results****"
      ],
      "metadata": {
        "id": "vjz66TJu6jXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store training and validation metrics\n",
        "train_loss_history = []\n",
        "train_acc_history = []\n",
        "val_loss_history = []\n",
        "val_acc_history = []\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        # Load the data to the current device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print epoch statistics\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    train_loss_history.append(epoch_loss)\n",
        "    train_acc_history.append(epoch_acc)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "    # Validation loop (optional)\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for images, labels in validation_loader:\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(validation_loader)\n",
        "    val_acc = 100 * val_correct / val_total\n",
        "    val_loss_history.append(val_loss)\n",
        "    val_acc_history.append(val_acc)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "lGeouddU6jXp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Now we make evaluations on the test data****"
      ],
      "metadata": {
        "id": "7DKtkBY86jXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if include_test:\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for images, labels in test_loader:\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Compute accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Accumulate loss\n",
        "            test_loss += loss.item()\n",
        "\n",
        "    # Compute average loss and accuracy\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = 100 * test_correct / test_total\n",
        "\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "tx8Ki_7A6jXv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV.1) Visualize the prediction"
      ],
      "metadata": {
        "id": "5vdFcgV46jXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_prediction(data_loader, model, n_images, class_names):\n",
        "    \"\"\"\n",
        "    Test the model on random predictions\n",
        "    Args:\n",
        "        data_loader: PyTorch DataLoader instance\n",
        "        model: Trained PyTorch model\n",
        "        n_images: Number of images to plot\n",
        "        class_names: List of class names (e.g., ['Cat', 'Dog'])\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    images, labels = next(iter(data_loader))  # Fetch a batch of images and labels\n",
        "\n",
        "    # Move images and labels to the appropriate device (e.g., GPU if available)\n",
        "    device = next(model.parameters()).device\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Get model predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)  # Get the predicted class indices\n",
        "\n",
        "    # Convert tensors to numpy arrays for visualization\n",
        "    images = images.cpu().numpy()\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    # Plot the images with predictions\n",
        "    plt.figure(figsize=(14, 15))\n",
        "    for i in range(min(n_images, len(images))):  # Ensure we don't exceed the batch size\n",
        "        plt.subplot(4, 3, i + 1)\n",
        "        image = np.transpose(images[i], (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
        "        if images[i].shape[0] == 1:  # Grayscale image\n",
        "            image = image.squeeze()\n",
        "            plt.imshow(image, cmap='gray')\n",
        "        else:  # RGB image\n",
        "            plt.imshow(image)\n",
        "\n",
        "        # Set title color based on prediction correctness\n",
        "        if predictions[i] == labels[i]:\n",
        "            title_obj = plt.title(f\"True: {class_names[labels[i]]}\\nPred: {class_names[predictions[i]]}\", color='g')\n",
        "        else:\n",
        "            title_obj = plt.title(f\"True: {class_names[labels[i]]}\\nPred: {class_names[predictions[i]]}\", color='r')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "mo-NfnVO6jXv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction(validation_loader, model, n_images=9, class_names=['Cat','Dog'])"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "a4vN_ojA6jXw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "if include_test:\n",
        "    plot_prediction(test_loader, model, n_images=9, class_names=['Cat','Dog'])"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "nIe1xFyL6jXw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV.2) Visualize training process"
      ],
      "metadata": {
        "id": "nRiblkwx6jXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to store the training history\n",
        "results = pd.DataFrame({\n",
        "    'epoch': range(1, num_epochs + 1),\n",
        "    'train_loss': train_loss_history,\n",
        "    'train_acc': train_acc_history,\n",
        "    'val_loss': val_loss_history,\n",
        "    'val_acc': val_acc_history\n",
        "})\n",
        "\n",
        "# Display the last few rows of the DataFrame\n",
        "print(results.tail())"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "NrjRg_-Y6jXw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(results['epoch'], results['train_loss'], label='Train Loss')\n",
        "plt.plot(results['epoch'], results['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "sNo7FXs26jXw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(results['epoch'], results['train_acc'], label='Train Accuracy')\n",
        "plt.plot(results['epoch'], results['val_acc'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-03-21T08:34:49.953Z"
        },
        "trusted": true,
        "id": "A6M_WXcf6jXw"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}